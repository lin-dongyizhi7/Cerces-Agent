













# 昇腾NPU分布式训练端到端分析及检测指标体系——设计文档


**目录**

[昇腾NPU分布式训练端到端分析及检测指标体系——设计文档	1](#_Toc215486606)

[一、	工作目标摘要	3](#_Toc215486607)

[二、	问题背景	3](#_Toc215486608)

[三、	监测指标体系总览	3](#_Toc215486609)

[四、	指标体系	3](#_Toc215486610)

[4.1	全过程监控指标	3](#_Toc215486611)

[4.2	分阶段监控指标	7](#_Toc215486612)

[4.2.1	数据加载阶段追踪指标	7](#_Toc215486613)

[4.2.2	前向传播阶段追踪指标	7](#_Toc215486614)

[4.2.3	反向计算阶段追踪指标	9](#_Toc215486615)

[4.2.4	梯度同步&参数更新阶段追踪指标	10](#_Toc215486616)

[4.2.5	分阶段监控指标总结	11](#_Toc215486617)

[五、	异常判断规则说明	13](#_Toc215486618)

[**5.1**	**重要指标项异常**	13](#_Toc215486619)

[**5.2**	**主要NPU操作异常**	14](#_Toc215486620)

[**5.2.1**	**训练吞吐量**	14](#_Toc215486621)

[**5.2.2**	**计算密集型核函数**	15](#_Toc215486622)

[**5.2.3**	**通信带宽**	15](#_Toc215486623)

[**5.3**	**次要NPU操作异常**	16](#_Toc215486624)

[**5.4**	**步内CPU操作异常**	17](#_Toc215486625)

[**5.4.1**	**核启动延迟分布**	18](#_Toc215486626)

[**5.4.2**	**内存拷贝速率**	18](#_Toc215486627)

[**5.5**	**步间CPU操作异常**	19](#_Toc215486628)

[**5.6**	**时间线视图辅助判断异常**	19](#_Toc215486629)

[**5.7**	**本章总结**	20](#_Toc215486630)

[**六、**	**性能劣化场景说明**	22](#_Toc215486631)



## 1 工作目标摘要
本项目聚焦大模型分布式训练全流程，构建覆盖从底层硬件到上层模型训练各环节的端到端监测指标体系。通过明确各训练阶段的核心监测对象，区分直接获取指标与量化计算指标，提供具体的指标计算方法、监测手段及异常判断规则，实现对训练过程中算力、性能、稳定性等问题的精准识别与定位，为优化训练效率、提升集群稳定性提供数据支撑。

## 2 问题背景
大模型分布式训练涉及AI芯片、存储、网络等复杂基础设施，且训练流程包含数据加载、前向传播、反向传播、梯度同步与参数更新等多个关键环节，各环节均存在潜在瓶颈。数据加载阶段易因IO效率低导致GPU空闲，前向与反向传播阶段面临高复杂度算子计算开销大的问题，梯度同步阶段存在分布式通信瓶颈等。同时，训练过程中硬件状态、资源占用等指标实时变化，缺乏清晰的指标分类和统一的量化标准，难以高效排查异常，因此亟需建立一套规范的监测指标体系。

## 3 监测指标体系总览
大模型分布式训练监测指标体系区分为直接获取指标和量化计算指标。直接获取指标指为通过工具或接口可直接采集到的原始数据；量化计算指标指基于原始数据，通过数学公式计算或与历史数据对比得到的衍生指标。同时，根据判定规则，可分为直接判定指标，以及对比确认的指标，其中对比确认指标采用动态基线建模和统计异常检测进行判定。

## 4 指标体系
### 4.1  全过程监控指标
全过程监控指标贯穿模型训练始终，聚焦硬件状态与基础资源占用，实时反映集群整体运行情况。

1. 全过程监控指标的核心采集命令为npu-smi info watch -i id -c chip_id -d delay_seconds -s watch_type ，用于查询指定芯片的监控数据。各参数的具体定义与获取方式如下：
+ Id: 设备id。通过npu-smi info -l命令查出的NPU ID即为设备id。
+ chip_id: 芯片id。通过npu-smi info -m命令查出的Chip ID即为芯片id。
+ delay_seconds: 每轮查询延迟时长，单位为秒。取值范围为1~100，默认为1秒。
+ watch_type: 监测类型。-p查询功率，-t查询温度，-a查询AI Core占用率，-i查询AI Cpu占用率，-c查询Ctrl Cpu占用率，-m查询内存占用率，-b查询内存带宽占用率

(T1)功率：功率是表征NPU硬件能耗状态的核心物理量，单位为瓦特（W），直接反映芯片当前的负载强度与供电系统的运行稳定性，是衡量硬件运行安全的基础指标。其数值高低与芯片计算任务的密集程度正相关，既能体现当前训练任务的负荷水平，也能提前预警供电不稳定、电源模块过载等潜在风险，为硬件保护与能耗优化提供关键依据。

(T2)温度：温度是表征 NPU 芯片热状态的核心指标，单位为摄氏度（℃），优先采集芯片核心区域温度（而非外壳温度），直接反映芯片的散热效率与当前计算负荷的匹配度，是保障硬件长期稳定运行的关键指标。核心温度过高会触发硬件自动降频机制（导致算力下降），严重时会引发保护性停机。

(T3)AI Core 占用率：AI Core 占用率是表征 NPU 核心计算单元利用效率的关键指标，单位为百分比（%），取值范围 0%~100%，直接反映芯片计算资源的繁忙程度与任务调度的合理性，是评估计算层性能的核心依据。占用率过低（如持续低于 50%）表明计算资源未充分利用，可能源于数据供应不足或算子优化不足；占用率过高（如持续 100%）则可能导致任务阻塞。

(T4) AI Cpu 占用率：AI Cpu 占用率是表征 NPU 轻量控制逻辑执行效率的指标，单位为百分比（%），直接反映芯片控制层（如指令下发、数据交互调度）的负载水平，是保障计算与控制协同的关键指标。AI Cpu 主要负责低复杂度控制任务，其占用率过高（如持续超 80%）会导致控制指令积压，进而延迟计算任务的启动与衔接.

(T5) Ctrl Cpu 占用率：Ctrl Cpu 占用率是表征集群协同调度能力的核心指标，单位为百分比（%），直接反映集群控制节点（如任务分配、资源调整）的负载强度，是保障分布式训练协同性的关键依据。Ctrl Cpu 承担跨节点任务调度职责，其占用率过高（如持续超 90%）通常意味着控制指令量激增（如多节点同时请求资源）或调度程序异常，会导致训练任务启动延迟、资源分配不均。

(T6) 内存占用率：内存占用率是表征 NPU 内存资源（含设备内存 / 显存、系统内存）使用情况的指标，单位为百分比（%），通过 “（已用内存 / 总内存）×100%” 计算得出，直接反映内存资源的充足程度与分配合理性，是避免训练中断的核心指标。内存占用率过高（如持续超 90%）易引发内存溢出（OOM），导致训练任务崩溃；也可能暴露内存泄漏（如未释放临时张量）问题。

(T7) 内存带宽占用率：内存带宽占用率是表征 NPU 内存数据传输繁忙程度的指标，单位为百分比（%），通过 “（实际传输带宽 / 硬件额定带宽）×100%” 计算得出（额定带宽可从 NPU 硬件手册获取），直接反映内存数据交互的效率，是影响训练速度的关键指标。带宽占用率过高（如持续超 95%）会导致数据读取 / 写入延迟显著增加，尤其在大规模张量传输场景下，会成为训练流程的瓶颈；也可能暴露数据传输逻辑未优化（如未压缩数据）的问题。

2. (T8)Python的GC耗时：Python的GC（垃圾回收）耗时是衡量Python运行时内存管理效率的指标，过长的GC耗时会占用宝贵的训练时间，降低训练吞吐量，尤其在大模型训练中，频繁的垃圾回收会严重影响训练效率，该指标是优化Python内存管理的关键依据。

通过Python内置gc模块自定义统计，在gc.collect()调用前后记录时间戳，计算每次垃圾回收的耗时，单位为毫秒（ms），每完成1个训练step记录1次。

3. (T9-T14)内存相关aclrt函数吞吐量：涵盖aclrtMemcpyAsync/aclrtMemcpy2dAsync、aclrtFree/aclrtFreeHost、aclrtMalloc/aclrtMallocAsync六个核心内存操作函数的吞吐量，单位为兆字节/秒（MB/s），直接反映NPU内存操作的效率。吞吐量高低关系到数据传输、内存分配与释放的效率，是评估内存管理性能的核心依据。

实际传输数据量直接读取接口入参count，结合数据类型字节数确定总数据量，通过CANN计时工具记录函数执行耗时，计算公式为吞吐量=实际传输数据量（Bytes）/执行耗时。

4. (T15)aclrtLaunchKernel启动时延：核函数启动时延是衡量NPU硬件与软件协同效率的关键指标，单位为微秒（μs），即核函数从调用到实际启动的时间差。时延过长表明核函数参数传递、硬件资源调度存在瓶颈，会直接影响计算任务的启动效率，进而拖慢整体训练进度，是优化核函数执行效率的核心指标。

通过CANN计时工具记录核函数从调用到实际启动的时间差，单位为微秒（μs），每100次调用统计1次平均时延，排除首次调用的冷启动耗时。

表 1 全过程监控指标总结

| 指标类型 | 监测对象 | 监测手段 | 异常原因 |
| --- | --- | --- | --- |
| 全过程运维指标 | (T1)功率 | _npu-smi info watch -i id -c chip_id -d delay_seconds -s p_ | 1. 硬件供电不稳定；<br/>2. 芯片负载过高导致功率过载；<br/>3. 散热系统故障引发功率波动 |
| | (T2)温度 | _npu-smi info watch -i id -c chip_id -d delay_seconds -s t_ | 1. 机房散热空调故障；<br/>2. 硬件风扇停转或积灰；<br/>3. 芯片长期高负载过热 |
| | (T3)AI Core 占用率 | _npu-smi info watch -i id -c chip_id -d delay_seconds -s a_ | 1. 训练任务调度异常（部分Core未分配任务）;<br/>2. 算子优化不足导致Core空闲 |
| | (T4)AI Cpu 占用率 | _npu-smi info watch -i id -c chip_id -d delay_seconds -s i_ | 1. AI Cpu控制程序异常；<br/>2. 控制指令发送过于频繁；<br/>3. 驱动程序资源泄漏 |
| | (T5)Ctrl Cpu 占用率 | _npu-smi info watch -i id -c chip_id -d delay_seconds -s c_ | 1. 集群控制程序异常；<br/>2. 控制指令量激增（多节点同时请求资源）；<br/>3. 控制节点硬件性能不足 |
| | (T6)内存占用率 | _npu-smi info watch -i id -c chip_id -d delay_seconds -s m_ | 1. 模型参数过大导致内存不足；<br/>2. 内存泄漏（未释放临时张量）；<br/>3. 多任务内存分配不合理 |
| | (T7)内存带宽占用率 | _npu-smi info watch -i id -c chip_id -d delay_seconds -s b_ | 1. 内存访问频繁（数据读取逻辑不合理）；<br/>2. 内存硬件故障；<br/>3. 数据传输未压缩 |
| | (T8)Python的GC耗时 | 自定义统计GC次数/耗时 | 1. Python对象创建过多；<br/>2. 内存管理不规范（未及时释放大对象）；<br/>3. 数据缓存逻辑不当（频繁创建 / 销毁大张量） |
| | (T9~T14)<br/>aclrtMemcpyAsync/ aclrtMemcpy2dAsync、aclrtFree/aclrtFreeHos、aclrtMalloc/ aclrtMallocAsync吞吐量 | 实际传输数据量直接使用入口参数count获取；<br/>调用CANN计时接口计算耗时 | 1. 内存碎片化（频繁小内存块分配）；<br/>2. 内存管理策略不当；<br/>3. CPU-GPU/NPU 跨设备数据交互频繁 |
| | (T15)aclrtLaunchKernel及对应自定义核函数的启动时延 | CANN计时 | 1. 核函数参数传递效率低；<br/>2. 硬件核资源竞争；<br/>3. 核函数编译优化不足 |


### 4.2  分阶段监控指标
根据训练阶段，可以将追踪指标分为数据加载、前向传播、反向传播、梯度同步与参数更新四个核心环节设置，精准定位各环节的性能瓶颈。

#### 4.2.1  数据加载阶段追踪指标
数据加载是训练流程的起始环节，其效率直接决定后续NPU是否会因数据供应不足而空闲，该阶段的核心监测指标为DataLoader吞吐量。

1. (D1)DataLoader吞吐量

指标定义：DataLoader吞吐量是衡量数据从存储介质加载到训练框架的效率指标，单位为（batch/s），直接反映数据预处理、IO读取等环节的协同性能。

核心作用：该指标是评估数据加载阶段是否存在瓶颈的核心依据，吞吐量过低会导致NPU长期空闲，严重影响训练效率。

获取细节：

·吞吐量最终的计算公式为：.

·batch_size为训练前在配置文件中预设的固定值，常见取值为32、64、128等，需根据模型大小和硬件内存灵活配置；

·batch_latency通过Python的Profiler机制追踪torch.utils.data.dataloader._BaseData LoaderIter.next函数的调用耗时获取，单位为秒（s）。

#### 4.2.2  前向传播阶段追踪指标
前向传播是模型计算的核心环节，通过算子运算生成预测结果，并为反向传播记录计算图，该阶段核心监测指标聚焦关键算子的执行效率与算力表现。

1. (F1)aclnnFlashAttentionScore

指标定义：该指标是Attention机制的核心算子指标，包含执行时间（单位：s）和算力（单位：TFLOPs）两个维度，直接反映大模型中注意力计算的效率。

核心作用：Attention计算是大模型前向传播的核心耗时环节，该指标的优化空间直接决定训练效率，是前向传播阶段的重点优化对象。

获取细节：

·算力计算公式为：.

·T为函数执行时间，通过CANN计时工具采集；

·N直接读取接口入参headNum；

·Sq（query序列长度）、Sk（key序列长度）、B（batch数）、D（头维度）通过aclGetStorageShape接口解析query张量的存储形状获取；

1. (F2-F3)aclnnMatmul, aclnnBatchMatMul

指标定义：这两个指标是矩阵乘法相关的核心算子指标，算力单位为TFLOPs，矩阵运算在模型参数计算中占比极高，其算力表现直接决定前向传播的整体速度。

核心作用：矩阵乘法的效率优化是提升前向计算速度的关键，该指标可精准定位矩阵维度不合理、硬件加速未启用等问题。

获取细节：

·算力计算公式为：.

·T为函数执行时间，通过CANN计时工具采集；

·B（batch数）、M（矩阵A行数）、N（矩阵B列数）、K（矩阵A列数/矩阵B行数）通过aclGetStorageShape接口解析输入张量获取；

1. (F4)aclnnFFN

指标定义：该指标是前馈神经网络层的核心性能指标，涵盖执行时间（单位：s）和算力（单位：TFLOPs），在混合专家机制（Moe）场景下，量化算力尤为关键。

核心作用：FFN层负责模型的特征提取与转换，其效率直接影响模型的表达能力与训练速度，是前向传播阶段的重要监测对象。

获取细节：

·算力计算公式为：

.

·T为函数执行时间，通过CANN计时工具采集；

·B（batch数）、S（序列长度）、Din（输入维度）、Dmid（中间层维度）通过aclGetStorageShape接口解析输入张量获取；

#### 4.2.3 反向计算阶段追踪指标
反向计算阶段的核心任务是计算模型参数的梯度，为参数更新提供依据，该阶段指标聚焦梯度计算的效率与耗时，直接影响训练迭代速度。

1. (B1)aclnnFlashAttentionScoreGrad

指标定义：该指标是Attention算子梯度计算的核心指标，算力单位为TFLOPs，梯度计算的复杂度不亚于正向计算，其效率直接决定反向传播的整体耗时。

核心作用：尤其在长序列场景下，该指标的优化空间显著，是提升反向传播效率的关键切入点。

获取细节：

·算力计算公式为：.

·T为函数执行时间，通过CANN计时工具采集；

·参数获取方式与F1一致，N为接口入参headNum，Sq、Sk、B、D通过解析query张量获取；

1. (B2-B3)aclnnMatmul, aclnnBatchMatMul

指标定义：这两个指标是矩阵乘法算子的梯度计算指标，算力单位为TFLOPs，梯度计算逻辑的优化程度直接影响反向传播的效率。

核心作用：该指标可精准定位矩阵梯度计算逻辑未优化、批量任务分配不均等问题，是反向计算阶段的重点监测对象。

获取细节：

·算力计算公式为：.

·参数B、M、N、K的获取方式与F2 - F3一致，T为梯度算子执行时间；

1. (B4)torch.autograd.backward

指标定义：该指标是反向传播的核心函数耗时指标，单位为毫秒（ms），torch.autograd.backward函数负责触发整体梯度计算，其耗时直接反映反向传播的整体效率。

核心作用：该指标是评估反向计算阶段性能的核心依据，可精准定位模型参数过多、梯度Checkpoint未启用等问题。

获取细节：

· 通过Python的Profiler机制记录函数从调用到执行完毕的总耗时，单位为毫秒（ms），排除梯度同步等额外耗时，仅统计纯梯度计算时间。

1. (B5)torch.autograd.grad

指标定义：该指标聚焦目标参数的梯度计算耗时，单位为毫秒（ms），常用于自定义梯度函数场景，其耗时长短直接反映自定义逻辑的优化程度。

核心作用：是排查自定义梯度函数逻辑复杂、计算范围不合理等问题的关键指标。

获取细节：

· 通过Python的Profiler机制采集函数耗时，单位为毫秒（ms），聚焦目标参数的梯度计算过程，避免其他参数干扰。

#### 4.2.4 梯度同步&参数更新阶段追踪指标
1. (G1-G4)hccl系列通信函数

指标定义：这四个指标是分布式集合通信的核心指标，计算结果为通信效率值，单位为吉字节/秒（GB/s），直接反映跨节点数据同步的速度。

核心作用：通信效率低下是分布式训练的常见瓶颈，该指标可精准定位网络带宽不足、通信拓扑不合理等问题。

获取细节：

·计算公式为：.

·T为函数执行时间，通过CANN计时工具采集；

·count（数据个数）、dataTypeSize（数据类型字节数，如FP16为2字节）从接口入口参数直接获取；

· k为系数，由通信操作类型确定（如hcclAllReduce的k=1，hcclBroadcast的k=0.5）；

1. (G5-G7)CANN流/事件同步耗时

指标定义：该类指标是CANN流与事件同步的耗时指标，单位为微秒（μs），流与事件的同步是保障计算与通信协同的关键。

核心作用：同步耗时过长会导致训练流程阻塞，影响各环节的衔接效率，是优化分布式训练协同性的重要指标。

获取细节：

·通过CANN事件机制直接采集同步操作的起止时间差，单位为微秒（μs），仅统计计算流与通信流、设备流与主机流的必要同步耗时。

#### 4.2.5 分阶段监控指标总结
表 2 分阶段监控指标总结

| 阶段 | 监测对象 | 计算方式 | 获取手段 | 异常原因 |
| :---: | --- | --- | --- | --- |
| 数据加载 | (D1)DataLoader吞吐量 | batch_size/batch_latency | batch_size:一般自行预先配置；<br/>Python的Profiler机制获取batch_latency | 1. 磁盘IO效率低（机械硬盘/未用RAID）；<br/>2. 预处理逻辑复杂（未用多进程）；<br/>3. 数据格式不合理 |
| 前向传播 | (F1)aclnnFlashAttentionScore | T：执行时间<br/>TFLOPs = 4×B×N×D×Sq×Sk/T | N: 接口入参 headNum；<br/>使用aclGetStorageShap解析query 张量得到Sq、Sk、B、D | 1. Attention算子未优化；<br/>2. 输入张量维度不合理；<br/>3. 硬件算力未充分利用 |
| | (F2-F3)aclnnMatmul, aclnnBatchMatMul | TFLOPs =B×M ×N×2K/T | 使用aclGetStorageShape解析输入张量得到 | 1. 矩阵维度未满足硬件对齐要求；<br/>2. 未启用低精度计算（如FP16）；<br/>3. 未调用硬件加速核心（如Tensor Core） |
| | (F4)aclnnFFN | T：执行时间<br/>TFLOPs(MoeFFN,quant) = 4×B×S×Di×Dmid +3×B×S×Dmid /T | 使用aclGetStorageShape解析输入张量得到 | 1. FFN层维度配置不合理；<br/>2. 混合专家机制调度低效；<br/>3. 量化精度选择不当导致算力损耗 |
| 反向计算 | (B1)aclnnFlashAttentionScoreGrad | TFLOPs = B× N × 8 × Sq × Sk × D/T | N接口入参 headNum；<br/>使用aclGetStorageShap解析 query 张量得到Sq、Sk、B、D | 1. 梯度计算未复用前向中间结果；<br/>2. Attention梯度算子实现冗余；<br/>3. 硬件对梯度计算指令支持不足 |
| | (B2-B3)aclnnMatmul, aclnnBatchMatMul | TFLOPs= B× M×N×2K /T | 使用aclGetStorageShape解析输入张量得到 | 1. 矩阵梯度计算逻辑未优化；<br/>2. 批量梯度处理任务分配不均；<br/>3. 张量数据格式转换频繁 |
| | (B4)torch.autograd.backward | 耗时 | Python的Profiler机制获取 | 1. 模型参数规模过大导致梯度计算量激增；<br/>2. 未启用梯度Checkpoint；<br/>3. 自动微分引擎优化开关未开启 |
| | (B5)torch.autograd.grad | 耗时 | Python的Profiler机制获取 | 1. 自定义梯度函数逻辑复杂；<br/>2. 梯度计算范围未合理限定；<br/>3. 多GPU/NPU梯度协同计算延迟 |
| 梯度同步&参数更新 | (G1-G4)hcclAllReduce/hcclBroadcast/hcclAllGather/hcclReduceScatter | k×count×dataTypeSize/T | count、dataTypeSize从入口参数获得；<br/>T：CANN事件机制；<br/>k：由操作类型获得 | 1. 网络带宽不足（未使用RDMA协议）；<br/>2. 跨节点通信拓扑不合理（跨机架传输）；<br/>3. 梯度数据未做压缩或量化处理 |
| | (G5-G7)aclrtSynchronizeStream(CANN流同步)、aclrtSynchronizeEvent/aclrtStreamWaitEvent(事件/流同步)耗时<br/> | 耗时 | CANN事件机制获取 | 1. 流同步时机设置不当（过早同步导致等待）；<br/>2. 流内任务堆积过多未拆分；<br/>3. 硬件流调度机制异常 |




## 5 异常判断规则说明
    1. **重要指标项异常**

在模型训练过程中，部分关键性能指标能够直接反映硬件平台及计算资源的实时运行状态。这些指标因其与系统稳定性、计算效率及潜在故障高度相关，被定义为“重要指标项”。针对此类指标，可采用基于阈值或趋势变化的简单规则进行异常检测，以实现对系统健康状态的快速评估与预警。

**数据来源**

功率（T1）、温度（T2）、AICore占用率（T3）、AICpu占用率（T4）、CtrlCpu占用率（T5）、内存占用率（T6）、内存宽带占用率（T7）。

**规则R1：静态阈值越界检测**

为每个指标()配置上限阈值()和（如适用）下限阈值()。若在连续k个采样周期内，指标值始终超出阈值范围，即满足：

则判定为异常并上报事件。

**规则R2：CUSUM动态趋势偏移检测**

针对具有缓变特性的指标（如()、()、()等），在静态阈值基础上引入CUSUM（Cumulative Sum Control Chart）方法，以检测尚未越界但呈现持续性偏移的早期异常。基于历史稳态运行数据，离线估计指标的正常均值与标准差，作为异常检测的基准参数。

实时维护如下累积和统计量，用于捕捉指标的持续性偏移趋势：



初始，其中为参考偏移量，取值范围为，用于调节对微小偏移的检测敏感度；为采样周期（与保持一致）。当累积统计量超过预设决策阈值（默认=5）时，即：



则判定为异常并上报事件。

    1. **主要NPU操作异常**

这部分数据反映大模型训练过程中与“算-存-网”三大核心维度直接相关的性能瓶颈或异常行为，是判断训练效率和系统健康状态的关键依据。由于这些指标通常具有明确的物理含义和可量化性，适合结合历史基线与实时观测进行异常检测。

        1. **训练吞吐量**

训练吞吐量可对整个训练过程进行宏观把控。训练初期易因初始化操作（如数据预热、缓存加载）出现吞吐量抖动，属于正常现象；若训练执行期出现异常，或数据读取时磁盘吞吐量无法支撑训练需求，则会导致吞吐量出现非预期波动，需重点关注。

**数据来源**

DataLoader相关操作吞吐量（D1）

**规则R3：对比训练吞吐量数据**

设当前训练任务为，第s个训练step的瞬时吞吐量观测值为（单位：byte/s）。设定为训练预热步长（工程建议取值50~200步，根据数据量级及预处理复杂度自适应调整），仅对的稳定阶段数据进行统计，规避启动阶段抖动干扰；定义窗口长度L（建议取值30~100步，与训练step时间粒度正相关），窗口滑动方式为“先进先出”，仅保留最近L个step的有效数据；

滑动吞吐量平均公式：



滑动吞吐量标准差公式：



其中，表示当前有效窗口大小（窗口未填满时取实际step数，填满后固定为L）；当时标记为无效值，不参与阶段对比；实时计算窗口内数据的平均值μ和标准差σ，以“均值±k×标准差”作为正常范围（k为灵敏度参数，默认2~3，对应95%~99.7%置信区间）。

        1. **计算密集型核函数**

计算是NPU训练过程中的核心高频操作。当算子实现低效、计算单元出现故障的时候，会极大影响训练过程的进行。因此对于计算密集型核函数进行监控可以最大限度检测到计算过程中出现的异常。

**数据来源**

aclnnFlashAttentionScore (F1)、aclnnMatmul(F2)、aclnnBatchMatMul (F3)、aclnnBatchMatMul (F3)、aclnnMatmul (B2)、aclnnBatchMatMul (B3)

**规则R4：对比基准FLOPS数据**

首先构建基准测试程序（Benchmark），在负载参数确定的情况下，对目标核函数进行全量性能测试，输出基准FLOPS（记为）。基准FLOPS定义为核函数在无干扰、无异常场景下的理论最优计算吞吐量，计算公式如下：



在实际训练过程中，实时采集每个rank（进程）上目标核函数的实际执行性能（r为rank编号，t为时间戳），计算相对性能比例，即实际性能相对于基准性能的占比：



对最近N个采样周期（如\(N=100\)）内的相对性能比例序列计算25分位数和75分位数，通过四分位距（IQR）确定异常波动阈值：







若，判定为“性能波动异常”。

        1. **通信带宽**

**数据来源**

hcclAllReduce (G1)、hcclBroadcast (G2)、hcclAllGather (G3)、hcclReduceScatter(G4)

在分布式NPU训练场景中，集合通信操作是跨节点/跨rank数据同步的核心环节，其通信带宽与延迟直接决定分布式训练的整体瓶颈。正常工况下，相同数据并行（DP）组内的通信时长一致性高，跨DP组的通信带宽具有可对比性。通过对集合通信操作的带宽指标进行实时监控，可及时发现网络链路故障、拓扑配置异常、通信调度冲突等问题，保障分布式训练的稳定性与效率。

按“DP组+通信操作类型”分组（如DP组1的AllReduce操作、DP组2的AllGather操作），采集最近M个采样周期的带宽数据，构成样本序列，其中，N为该DP组内的rank数量，op为通信操作类型；假设样本序列服从正态分布，其中为均值，为标准差。

**规则R5：组内单rank异常检验**

对于当前采样周期t下DP组g内rankr的带宽，若满足：



则初步判定该rank的通信带宽“单节点异常”，标记为候选异常。

**规则R6：跨DP组异常检验**

针对相同通信操作类型op，计算所有正常DP组（无候选异常的组）的平均带宽：



其中为当前无候选异常的DP组集合。若某DP组g的均值满足：



（其中为所有正常DP组均值的标准差），则判定该DP组“整体通信异常”。

    1. **次要NPU操作异常**

为保障检测框架的轻量级特性，避免对训练任务产生额外性能开销，核心监控范围仅聚焦于关键NPU内核操作，即前述计算密集型核函数、通信相关内核等。但需注意，未纳入核心监控范围的次要NPU内核操作，若存在性能劣化，仍可能导致整体训练效率下降甚至任务阻塞。因此，需设计专项衡量指标，间接表征次要NPU内核的运行状态。

**数据来源**

DataLoader 吞吐量 (D1)、aclnnFlashAttentionScore (F1)、aclnnMatmul (F2)、aclnnBatchMatMul (F3)、aclnnFFN (F4)、、aclnnFlashAttentionScoreGrad (B1)aclnnMatmul (B2)、aclnnBatchMatMul (B3)等

**规则R7：次要NPU操作异常检验**



![](https://cdn.nlark.com/yuque/0/2025/png/52875135/1764724930347-69ea3f96-494c-4d72-8876-b3113dd5dc31.png)

次要NPU内核空窗占比公式：



其中，代表所有次要NPU内核的耗时，可以由这一步的耗时减去监测到的内核函数的的耗时总和获得；代表训练步骤中扣除步间CPU操作耗时后的有效计算时段。

通过实时监测的数值变化趋势（如短期内突增、持续高于阈值），可间接判断次要NPU内核是否存在性能异常：若显著上升，通常表明未监控的次要内核存在执行耗时增加、调度阻塞等问题，需进一步排查该类内核的实现效率或运行状态，避免其占用过多NPU计算资源，影响核心任务的执行进度。

    1. **步内CPU操作异常**

步内CPU操作异常是大规模LLM分布式训练中隐性性能损耗的重要来源，主要表现为CPU侧操作与GPU核执行的协同失衡，导致GPU资源闲置或训练流程阻塞。

        1. **核启动延迟分布**

**数据来源**

aclrtLaunchKernel (T15)

**规则R8：核启动延迟分布的判断**

核启动延迟定义为GPU核的“提交时间戳”与“实际执行开始时间戳”之间的时间差，其分布特征是诊断步内CPU操作异常的核心指标。在健康的训练流程中，核启动延迟主要受集体通信算子的天然差异影响，呈现均匀的线性累积分布。而步内CPU操作异常会破坏这一分布规律，导致延迟分布呈现“陡峭化”特征。

核启动延迟（L）定义为：



I为训练rank编号，j：NPU核编号；

：第i个rank中第j个核的CPU提交时间戳（单位：ms）；

：第i个rank中第j个核的GPU开始执行时间戳（单位：ms）；

采集核函数的启动延迟，可以定义均匀性系数，



判定阈值：。

        1. **内存拷贝速率**

内存拷贝速率是步内CPU与NPU数据交互效率的直接反映，涵盖CPU主机内存与NPU设备内存之间的双向数据传输。

**数据来源**

**aclrtMemcpyAsync (T9)、aclrtMemcpy2dAsync (T10)、aclrtFree (T11)**

**aclrtFreeHost (T12)、aclrtMalloc (T13)、aclrtMallocAsync (T14)**

**规则R9：内存拷贝速率**

内存拷贝速率分为**主机到设备（Host-to-Device,H2D）**和**设备到主机（Device-to-Host,D2H）**两个方向，核心公式如下：

,

分别为H2D、D2H方向的内存拷贝速率（单位：GB/s），速率越高表示数据交互效率越强；对于采集到的数据可以进行关于阈值范围的判断。

    1. **步间CPU操作异常**

步间CPU操作是指两个连续训练步骤之间的CPU侧操作，主要包括数据加载等任务。这类操作虽不直接参与NPU计算，但会占用训练周期中的关键时间窗口——若步间操作耗时过长，会直接压缩NPU的有效计算时间，导致训练步骤总耗时增加，整体效率下降。因此，需通过量化指标明确步间操作的时间占比，实现异常的及时发现。

**数据来源**

DataLoader 吞吐量 (D1)、aclnnFlashAttentionScore (F1)、aclnnMatmul (F2)、aclnnBatchMatMul (F3)、aclnnFFN (F4)、、aclnnFlashAttentionScoreGrad (B1)aclnnMatmul (B2)、aclnnBatchMatMul (B3)等

**规则R10：步间CPU操作异常**

![](https://cdn.nlark.com/yuque/0/2025/png/52875135/1764724930633-43a8b46b-b73f-475a-a0db-633142a3a986.png)



其中，代表步间CPU操作的耗时（数据加载器执行前最后一个内核与执行后第一个内核的时间差值），代表训练步骤的总耗时。

    1. **时间线视图辅助判断异常**

尽管通过上述量化指标可覆盖绝大多数常见异常场景，但在大规模分布式训练中，仍可能存在复杂的隐性异常（如多模块间的交互冲突、偶发的资源调度异常等），这类异常难以通过单一指标精准捕捉。为此，引入时间线视图作为辅助诊断手段，通过可视化方式直观呈现各模块的执行时序，帮助测试人员定位异常根源。



**数据来源**

Python 的 GC 耗时 (T8)、aclrtMemcpyAsync (T9)、aclrtMemcpy2dAsync (T10)、aclrtFree (T11)、aclrtFreeHost (T12)、aclrtMalloc (T13)、aclrtMallocAsync (T14)、aclrtLaunchKernel (T15)、DataLoader 吞吐量 (D1)、aclnnFlashAttentionScore (F1)、aclnnMatmul (F2)、aclnnBatchMatMul (F3)、aclnnFFN (F4)、aclnnFlashAttentionScore (F1)、aclnnMatmul (F2)、aclnnBatchMatMul (F3)、aclnnFFN (F4)、aclnnFlashAttentionScore (F1)、aclnnMatmul (F2)、aclnnBatchMatMul (F3)、aclnnFFN (F4)![](https://cdn.nlark.com/yuque/0/2025/png/52875135/1764724930936-4551b101-04dd-41d9-bc93-a2d22b7a86fc.png)

采用Perfetto工具绘制主机上的函数执行时间线视图。Perfetto是一款开源的性能分析工具，支持高分辨率的时序数据采集与可视化展示，能够清晰呈现CPU函数调用、NPU内核执行、数据传输等操作的时间分布与交互关系。测试人员可通过时间线视图，直观观察各操作的启动与结束时间、执行时长及资源占用情况，快速定位“CPU操作阻塞NPU执行”“多函数时序冲突”等隐性异常，为问题排查提供直接的视觉依据。



    1. **本章总结**

| **类别** | **指标项** | **异常报告规则** | **数据来源** |
| --- | --- | --- | --- |
| **重要指标项异常** | 设备指标 | **R1：静态阈值越界检测**<br/>若连续k个采样周期内指标值始终超出预设上下限阈值，则判定为异常。<br/><br/>**R2：CUSUM动态趋势偏移检测**<br/>对缓变指标维护累积和统计量，大于5时判定为异常。 | T1–T7 |
| **主要NPU操作异常**<br/>** ** | 训练吞吐量 | **R3：对比训练吞吐量数据**<br/>在预热阶段后，使用滑动窗口计算均值与标准差，以“均值 ± k×标准差”（k=2~3）作为正常范围；超出则异常。 | D1 |
| | 计算密集型核函数 | **R4：对比基准FLOPS数据**<br/>计算实际FLOPS与基准FLOPS的相对比例 _Rr_,_t_，基于IQR（四分位距）判断是否异常： | F1–F4, B1–B3 |
| | 通信带宽 | **R5：组内单rank异常检验**<br/>若某rank带宽偏离组均值±3σ，则标记为候选异常。<br/><br/>**R6：跨DP组异常检验**<br/>若某DP组整体带宽偏离所有正常组均值±3σ，则判定为整体异常。 | G1–G4 |
| **次要NPU操作异常** | 未被直接监控的次要NPU内核 | **R7：次要NPU操作异常检验**<br/>计算次要内核空窗占比，若该值突增或持续高于阈值，视为异常。 | D1, F1–F4, B1–B3 等 |
| **步内CPU操作异常 ** | 核启动延迟 | **R8：核启动延迟分布判断**<br/>计算均匀性系数 _CU_判定异常。 | T15 |
| | 内存拷贝速率 | **R9：内存拷贝速率判断**<br/>计算拷贝速率_，_若低于/高于预设阈值范围，则异常。 | T9–T14 |
| **步间CPU操作异常** | 步间CPU操作耗时占比 | **R10：步间CPU操作异常**<br/>计算步间操作占比，若该值过高（如显著超过历史基线），则视为异常。 | D1, F1–F4, B1–B3 等 |
| **辅助诊断手段** | 多模块执行时序交互 | **时间线视图辅助判断异常**<br/>通过 Perfetto 可视化各操作时间线，人工识别隐性异常。 | T8–T15, D1, F1–F4, B1–B3 等 |


1. **性能劣化场景说明**

| **维度** | **根因分类** | **典型性能劣化表现** | **本指标体系对应判断规则** | **严重程度** |
| :---: | --- | --- | --- | --- |
| **硬件层** | 供电稳定性衰减 | NPU功率波动±15%以上，训练吞吐量周期性骤降，单step耗时波动幅度超30%，偶发硬件降频 | R1（功率阈值越界）、R2（CUSUM动态趋势偏移） | 高 |
| | 散热效能下降 | NPU温度≥85℃并持续升高，AI Core主动降频导致计算效率下降20%以上，吞吐量随温度升高线性降低 | R1（温度阈值）、R2（温度趋势）、R4（计算效率） | 高 |
| | 芯片算力衰减 | AI Core峰值FLOPS下降至基准值70%以下，核心算子（aclnnMatmul）执行耗时增加50%，算力利用率持续低于60% | R1（算力利用率）、R4（算子效率） | 中 |
| | 内存硬件瓶颈 | 内存带宽利用率骤降至40%以下，内存拷贝（aclrtMemcpyAsync）速率下降60%，step耗时中内存操作占比超50% | R1（带宽利用率）、R9（内存拷贝效率） | 高 |
| | 通信硬件损耗 | RDMA网卡吞吐量降至理论值50%以下，hcclAllReduce通信耗时增加2倍，跨节点数据同步成为性能瓶颈 | R5（通信带宽）、R6（跨节点延迟） | 高 |
| **代码和模型层** | 核心算子实现低效 | 注意力算子（aclnnFlashAttention）FLOPS仅为基准值40%，前向传播耗时中算子占比超80% | R4（算子FLOPS） | 中 |
| | 梯度计算冗余 | 反向传播耗时比正常状态增加1倍，aclnnFlashAttentionScoreGrad重复计算，内存占用额外增加30% | R4（梯度算子效率） | 中 |
| | 内存管理失当 | 内存碎片化率超60%，aclrtMalloc调用成功率下降，临时张量未释放导致内存占用率长期≥90% | R1（内存占用率）、R9（内存操作效率） | 中 |
| | Python层内存泄漏 | Python GC单次耗时超500ms，训练每100步内存占用增长10%，最终触发OOM预警 | R1（T8：GC耗时） | 低 |
| | 自动微分引擎未优化 | Torch.autograd.backward耗时占比超反向传播总耗时60%，自定义梯度函数未适配昇腾算子 | 无 | 低 |
| | 梯度Checkpoint缺失 | 大模型训练时反向传播内存占用超硬件上限80%，需重复读取输入数据导致IO耗时增加 | 无 | 低 |
| | 混合专家调度失衡 | MoE模型aclnnFFN算子FLOPS波动±40%，部分专家节点负载100%而部分空闲率超80% | R4（MoE算子效率） | 中 |
| | 核函数编译缺陷 | aclrtLaunchKernel启动时延超100μs，核函数未启用Tensor Core加速，计算效率下降30% | R4（计算效率）、R8（核启动时延） | 低 |
| **数据层** | 数据格式不兼容 | DataLoader解析非标准格式数据耗时增加2倍，H2D数据拷贝速率下降40%，batch_latency超正常均值1.8倍 | R3（DataLoader吞吐量）、R9（数据拷贝效率） | 中 |
| | 预处理逻辑臃肿 | CPU预处理耗时占step总耗时比例超50%，多进程预处理出现锁竞争，batch处理时延波动超100ms | R10（CPU操作占比） | 低 |
| | batch配置不合理 | batch_size过大导致内存利用率≥95%引发频繁换页，过小则使AI Core利用率≤50%，吞吐量下降 | R1（内存/核心利用率）、R3（吞吐量） | 中 |
| | 数据缓存策略失效 | 缓存命中率≤30%，重复读取磁盘数据导致IO负载增加，DataLoader吞吐量波动±25% | R1（T8：缓存耗时）、R3（IO吞吐量） | 低 |
| **部署层** | 资源调度失衡 | AI Core分配不均，部分Core利用率100%而部分≤30%，多任务共享时吞吐量下降40%，核资源竞争激烈 | R1（Core利用率）、R3（吞吐量）、R8（核竞争指标） | 中 |
| | DP组拓扑配置错误 | DP组内rank通信延迟差异超3倍，部分节点通信失败导致训练卡死后重试，效率下降50% | R5（组内带宽）、R6（rank延迟） | 中 |
| | 流同步时机不当 | aclrtSynchronizeStream耗时超500ms，计算流与通信流过早同步导致NPU空闲率≥35%，训练卡顿 | 无 | 中 |
| | 梯度数据未优化 | 梯度未压缩导致通信数据量增加3倍，hccl通信耗时占step比例超40%，带宽占用率≥95% | R5（通信带宽）、R6（通信耗时） | 中 |
| | CPU-NPU协同不畅 | 核启动延迟均匀性系数＜0.7，CPU向NPU传数频繁导致内存拷贝占比超30%，计算与传输衔接断层 | R8（核延迟均匀性）、R9（数据交互效率） | 中 |
| | 步间CPU操作冗余 | 步间数据准备、日志打印等操作耗时占step比例超50%，NPU有效计算时间被压缩至40%以下 | R10（步间CPU耗时占比） | 中 |
| | 次要内核性能劣化 | 次要内核空窗占比（V_minority）≥40%，辅助操作耗时增加导致step总耗时延长20%，主流程受牵连 | R7（空窗占比指标） | 低 |
| | 多模块时序冲突 | 训练偶发1-3s卡顿，单一指标无异常，时间线显示CPU调用、NPU计算、数据传输时序重叠阻塞 | 时间线视图辅助 | 中 |






